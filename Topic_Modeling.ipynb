{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95e4c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Versions</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>License</th>\n",
       "      <th>Views</th>\n",
       "      <th>Download</th>\n",
       "      <th>Kernels</th>\n",
       "      <th>Topics</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Card Fraud Detection</td>\n",
       "      <td>Anonymized credit card transactions labeled as...</td>\n",
       "      <td>Machine Learning Group - ULB</td>\n",
       "      <td>1241</td>\n",
       "      <td>Version 2,2016-11-05|Version 1,2016-11-03</td>\n",
       "      <td>crime\\nfinance</td>\n",
       "      <td>CSV</td>\n",
       "      <td>144 MB</td>\n",
       "      <td>ODbL</td>\n",
       "      <td>442,136 views</td>\n",
       "      <td>53,128 downloads</td>\n",
       "      <td>1,782 kernels</td>\n",
       "      <td>26 topics</td>\n",
       "      <td>https://www.kaggle.com/mlg-ulb/creditcardfraud</td>\n",
       "      <td>The datasets contains transactions made by cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European Soccer Database</td>\n",
       "      <td>25k+ matches, players &amp; teams attributes for E...</td>\n",
       "      <td>Hugo Mathien</td>\n",
       "      <td>1046</td>\n",
       "      <td>Version 10,2016-10-24|Version 9,2016-10-24|Ver...</td>\n",
       "      <td>association football\\neurope</td>\n",
       "      <td>SQLite</td>\n",
       "      <td>299 MB</td>\n",
       "      <td>ODbL</td>\n",
       "      <td>396,214 views</td>\n",
       "      <td>46,367 downloads</td>\n",
       "      <td>1,459 kernels</td>\n",
       "      <td>75 topics</td>\n",
       "      <td>https://www.kaggle.com/hugomathien/soccer</td>\n",
       "      <td>The ultimate Soccer database for data analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TMDB 5000 Movie Dataset</td>\n",
       "      <td>Metadata on ~5,000 movies from TMDb</td>\n",
       "      <td>The Movie Database (TMDb)</td>\n",
       "      <td>1024</td>\n",
       "      <td>Version 2,2017-09-28</td>\n",
       "      <td>film</td>\n",
       "      <td>CSV</td>\n",
       "      <td>44 MB</td>\n",
       "      <td>Other</td>\n",
       "      <td>446,255 views</td>\n",
       "      <td>62,002 downloads</td>\n",
       "      <td>1,394 kernels</td>\n",
       "      <td>46 topics</td>\n",
       "      <td>https://www.kaggle.com/tmdb/tmdb-movie-metadata</td>\n",
       "      <td>Background\\nWhat can we say about the success ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global Terrorism Database</td>\n",
       "      <td>More than 170,000 terrorist attacks worldwide,...</td>\n",
       "      <td>START Consortium</td>\n",
       "      <td>789</td>\n",
       "      <td>Version 2,2017-07-19|Version 1,2016-12-08</td>\n",
       "      <td>crime\\nterrorism\\ninternational relations</td>\n",
       "      <td>CSV</td>\n",
       "      <td>144 MB</td>\n",
       "      <td>Other</td>\n",
       "      <td>187,877 views</td>\n",
       "      <td>26,309 downloads</td>\n",
       "      <td>608 kernels</td>\n",
       "      <td>11 topics</td>\n",
       "      <td>https://www.kaggle.com/START-UMD/gtd</td>\n",
       "      <td>Context\\nInformation on more than 170,000 Terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitcoin Historical Data</td>\n",
       "      <td>Bitcoin data at 1-min intervals from select ex...</td>\n",
       "      <td>Zielak</td>\n",
       "      <td>618</td>\n",
       "      <td>Version 11,2018-01-11|Version 10,2017-11-17|Ve...</td>\n",
       "      <td>history\\nfinance</td>\n",
       "      <td>CSV</td>\n",
       "      <td>119 MB</td>\n",
       "      <td>CC4</td>\n",
       "      <td>146,734 views</td>\n",
       "      <td>16,868 downloads</td>\n",
       "      <td>68 kernels</td>\n",
       "      <td>13 topics</td>\n",
       "      <td>https://www.kaggle.com/mczielinski/bitcoin-his...</td>\n",
       "      <td>Context\\nBitcoin is the longest running and mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  \\\n",
       "0  Credit Card Fraud Detection   \n",
       "1     European Soccer Database   \n",
       "2      TMDB 5000 Movie Dataset   \n",
       "3    Global Terrorism Database   \n",
       "4      Bitcoin Historical Data   \n",
       "\n",
       "                                            Subtitle  \\\n",
       "0  Anonymized credit card transactions labeled as...   \n",
       "1  25k+ matches, players & teams attributes for E...   \n",
       "2                Metadata on ~5,000 movies from TMDb   \n",
       "3  More than 170,000 terrorist attacks worldwide,...   \n",
       "4  Bitcoin data at 1-min intervals from select ex...   \n",
       "\n",
       "                          Owner  Votes  \\\n",
       "0  Machine Learning Group - ULB   1241   \n",
       "1                  Hugo Mathien   1046   \n",
       "2     The Movie Database (TMDb)   1024   \n",
       "3              START Consortium    789   \n",
       "4                        Zielak    618   \n",
       "\n",
       "                                            Versions  \\\n",
       "0          Version 2,2016-11-05|Version 1,2016-11-03   \n",
       "1  Version 10,2016-10-24|Version 9,2016-10-24|Ver...   \n",
       "2                               Version 2,2017-09-28   \n",
       "3          Version 2,2017-07-19|Version 1,2016-12-08   \n",
       "4  Version 11,2018-01-11|Version 10,2017-11-17|Ve...   \n",
       "\n",
       "                                        Tags Data Type    Size License  \\\n",
       "0                             crime\\nfinance       CSV  144 MB    ODbL   \n",
       "1               association football\\neurope    SQLite  299 MB    ODbL   \n",
       "2                                       film       CSV   44 MB   Other   \n",
       "3  crime\\nterrorism\\ninternational relations       CSV  144 MB   Other   \n",
       "4                           history\\nfinance       CSV  119 MB     CC4   \n",
       "\n",
       "           Views          Download        Kernels     Topics  \\\n",
       "0  442,136 views  53,128 downloads  1,782 kernels  26 topics   \n",
       "1  396,214 views  46,367 downloads  1,459 kernels  75 topics   \n",
       "2  446,255 views  62,002 downloads  1,394 kernels  46 topics   \n",
       "3  187,877 views  26,309 downloads    608 kernels  11 topics   \n",
       "4  146,734 views  16,868 downloads     68 kernels  13 topics   \n",
       "\n",
       "                                                 URL  \\\n",
       "0     https://www.kaggle.com/mlg-ulb/creditcardfraud   \n",
       "1          https://www.kaggle.com/hugomathien/soccer   \n",
       "2    https://www.kaggle.com/tmdb/tmdb-movie-metadata   \n",
       "3               https://www.kaggle.com/START-UMD/gtd   \n",
       "4  https://www.kaggle.com/mczielinski/bitcoin-his...   \n",
       "\n",
       "                                         Description  \n",
       "0  The datasets contains transactions made by cre...  \n",
       "1  The ultimate Soccer database for data analysis...  \n",
       "2  Background\\nWhat can we say about the success ...  \n",
       "3  Context\\nInformation on more than 170,000 Terr...  \n",
       "4  Context\\nBitcoin is the longest running and mo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'voted-kaggle-dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867913c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subtitle       104\n",
       "Versions         5\n",
       "Tags           542\n",
       "Views            5\n",
       "Download        15\n",
       "Kernels        944\n",
       "Topics         592\n",
       "Description      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03f9284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0    The datasets contains transactions made by cre...\n",
       " 1    The ultimate Soccer database for data analysis...\n",
       " 2    Background\\nWhat can we say about the success ...\n",
       " 3    Context\\nInformation on more than 170,000 Terr...\n",
       " 4    Context\\nBitcoin is the longest running and mo...\n",
       " Name: Description, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Description'].fillna('No description', inplace=True)\n",
    "\n",
    "missing_descriptions = data['Description'].isnull().sum()\n",
    "missing_descriptions, data['Description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c0cd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the datasets contains transactions made by cre...\n",
       "1    the ultimate soccer database for data analysis...\n",
       "2    background\\nwhat can we say about the success ...\n",
       "3    context\\ninformation on more than  terrorist a...\n",
       "4    context\\nbitcoin is the longest running and mo...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "data['Description'] = data['Description'].apply(normalize_text)\n",
    "\n",
    "data['Description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b904587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "data dataset use model images set contains context features used\n",
      "Topic 1:\n",
      "dataset movie movies data pokemon time number model learning residual\n",
      "Topic 2:\n",
      "dataset data context acknowledgements number team content time contains inspiration\n",
      "Topic 3:\n",
      "data dataset content player number game information time contains file\n",
      "Topic 4:\n",
      "data dataset contains information number available content set acknowledgements database\n",
      "Topic 5:\n",
      "race horse time nominal data taken kumar marathon max zillow\n",
      "Topic 6:\n",
      "data dataset time content acknowledgements context information inspiration state health\n",
      "Topic 7:\n",
      "data university dataset number information content context use contains acknowledgements\n",
      "Topic 8:\n",
      "data dataset year country content world total years information context\n",
      "Topic 9:\n",
      "dataset data content contains context text price acknowledgements inspiration information\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "data_vectorized = vectorizer.fit_transform(data['Description'])\n",
    "\n",
    "number_of_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "lda.fit(data_vectorized)\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(lda, vectorizer.get_feature_names_out(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1efffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.025*\"train\" + 0.017*\"mile\" + 0.015*\"speech\" + 0.015*\"coordinate\" + 0.014*\"running\" + 0.014*\"twitter\" + 0.013*\"speaker\" + 0.013*\"removed\" + 0.010*\"taking\" + 0.009*\"duplicate\"\n",
      "Topic: 1 \n",
      "Words: 0.367*\"yet\" + 0.239*\"description\" + 0.014*\"pretrained\" + 0.011*\"model\" + 0.008*\"trained\" + 0.008*\"cell\" + 0.007*\"architecture\" + 0.006*\"transferable\" + 0.005*\"feature\" + 0.005*\"depth\"\n",
      "Topic: 2 \n",
      "Words: 0.024*\"borough\" + 0.019*\"york\" + 0.018*\"weather\" + 0.015*\"text\" + 0.012*\"city\" + 0.010*\"new\" + 0.009*\"nyc\" + 0.009*\"progress\" + 0.009*\"goal\" + 0.009*\"book\"\n",
      "Topic: 3 \n",
      "Words: 0.055*\"song\" + 0.030*\"music\" + 0.026*\"audio\" + 0.021*\"genre\" + 0.020*\"closed\" + 0.017*\"max\" + 0.013*\"surface\" + 0.012*\"care\" + 0.012*\"adding\" + 0.011*\"relative\"\n",
      "Topic: 4 \n",
      "Words: 0.025*\"nationality\" + 0.020*\"birth\" + 0.019*\"abbreviation\" + 0.019*\"improving\" + 0.018*\"word\" + 0.016*\"specie\" + 0.014*\"facility\" + 0.012*\"gas\" + 0.010*\"california\" + 0.009*\"key\"\n",
      "Topic: 5 \n",
      "Words: 0.027*\"customer\" + 0.024*\"candidate\" + 0.016*\"ranking\" + 0.016*\"brazilian\" + 0.016*\"october\" + 0.015*\"back\" + 0.015*\"east\" + 0.014*\"al\" + 0.014*\"election\" + 0.014*\"binary\"\n",
      "Topic: 6 \n",
      "Words: 0.039*\"solar\" + 0.029*\"generation\" + 0.023*\"education\" + 0.018*\"nltk\" + 0.017*\"unzip\" + 0.015*\"sun\" + 0.015*\"python\" + 0.014*\"canonical\" + 0.013*\"metadata\" + 0.013*\"package\"\n",
      "Topic: 7 \n",
      "Words: 0.023*\"university\" + 0.014*\"survey\" + 0.014*\"activity\" + 0.012*\"word\" + 0.012*\"school\" + 0.011*\"educational\" + 0.010*\"student\" + 0.010*\"college\" + 0.008*\"mass\" + 0.008*\"stanford\"\n",
      "Topic: 8 \n",
      "Words: 0.011*\"game\" + 0.010*\"player\" + 0.007*\"team\" + 0.006*\"project\" + 0.006*\"language\" + 0.005*\"season\" + 0.005*\"city\" + 0.005*\"type\" + 0.005*\"result\" + 0.005*\"health\"\n",
      "Topic: 9 \n",
      "Words: 0.006*\"file\" + 0.005*\"column\" + 0.005*\"day\" + 0.004*\"set\" + 0.004*\"car\" + 0.004*\"state\" + 0.004*\"image\" + 0.004*\"use\" + 0.004*\"year\" + 0.004*\"see\"\n",
      "\n",
      "Coherence Score:  0.3737504243162258\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel, TfidfModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "documents = data['Description'].fillna('No description').tolist()\n",
    "\n",
    "stop_words = set(stopwords.words('english')) | {'additional', 'stopword1', 'stopword2'}\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(doc):\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "\n",
    "texts = [preprocess(doc) for doc in documents]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.3)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lda_model = LdaModel(corpus_tfidf, num_topics=10, id2word=dictionary, passes=20, alpha='auto', eta='auto')\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc098a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
